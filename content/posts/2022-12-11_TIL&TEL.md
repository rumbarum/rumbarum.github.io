---
title: " TIL&TEL 22.12.05~22.12.11  "
date: "2022-12-11T01:23:45.678Z"
template: "post"
draft: false
slug: "/posts/TIL&TEL_22-12-11/"
category: "TIL&TEL"
tags:
- "TIL"
- "TEL"


description: " 22.12.05~22.12.11 배운것, 씨름한것들 "
---

## TIL( Today I Learned)

### 22-12-05 월

- PHASE 1 9-12 / 6
    - 비용 계산
        - 트래픽 공통
            - 100GB out 공짜
            - 그 이후
                - $ 0.126 / GB
        - rds 단순
            - 컴퓨팅
                - acu
                    - 1ACU는 2GiB의 메모리와 해당하는 컴퓨팅 및 네트워킹을 제공
                    - USD 0.2 per Aurora Capacity Unit hour running Aurora PostgreSQL Serverless v2
            - 저장소
                - USD 0.120 per GB-month of consumed storage for Aurora PostgreSQL
                - 
                - I/OPS
                    - USD 0.24 per 1 million I/O requests for Aurora PostgreSQL
            - 트래픽
        - rds aurora
            - 컴퓨팅
                - acu
                    - 1ACU는 2GiB의 메모리와 해당하는 컴퓨팅 및 네트워킹을 제공
                    - USD 0.2 per Aurora Capacity Unit hour running Aurora PostgreSQL Serverless v2
            - 저장소
                - USD 0.120 per GB-month of consumed storage for Aurora PostgreSQL
                - 
                - I/OPS
                    - USD 0.24 per 1 million I/O requests for Aurora PostgreSQL
            - 트래픽
        - ec2 - ebs
            - 컴퓨팅
                - 
            - 저장소
                - 0.114 per GB-month of General Purpose SSD (gp2) provisioned storage - Asia Pacific (Seoul)
            - 트래픽
        - drex 내부 저장
            - 
            - 컴퓨팅
                - acu
                    - 
            - 저장소
                - $0.125/GB-month 
                - I/OPS
            - 트래픽
    - 람다 
        - limit 설정이 가능한가?
            -  [동시성 및 크기 조정 제어](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/invocation-scaling.html)
            - 또는 알림?
                - concurrency
                    - 동시 처리 진행량 늘리기 기본 500
        - database Proxy 
            - 양이 늘어난다면 이것 처리도 필요하다 db connection managing
        - 의존성을 도커로 말아서 제공 - 의존성 관리 편해짐, 코드 관리 불편해짐
            -  aws ecr 사용 필요
        - 비동기 호출
            - 함수 실행 결과에 상관없이 전달 여부만 전달
            - 실패시 이벤트 대기열 대시 후 진행
        - 동기 호출
            - 실패시 실패에러 전달 X
            - cloudwatch logs에 에러로그 출력
    - 
    - yaml 선택적 적용 -> 가능
        - Condition 변수
        - 
    - lambda 변수 은닉화
        - ENV VAR
            - 코드 변경없이 변수 변경을 위해 제공중
            - Docker 이미지 사용?
    - 후가공 프로세스
        - flow  chart
        - 서빙용으로 데이터 가공
        - 가공 schema
            - 분석모듈
            - 필터
            - user_stat
- PHASE 2 13-16 / 6
    - \~~~~
- PHASE 3 16-18 / 4
- 

### 22-12-06 화

- PHASE 1 9-12 / 6
    - 수집
    - 분석
    - 감시
    - 
    - 람다 왜 에러 났음...?? 
        - vpc flow log
            - [ERROR] DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input synta 시작
                -  에러 쌓이기 시작하다가, 누적되면서 파싱하는데 시간소모되서 해결 못함
            - Task timed out after 10.08 seconds
        - streamToRDB
            - Task timed out 
                - 이벤트 7개 처리에
                    - 10초 넘기기 시작
                    - 왜...?
                - DB 커넥션 풀 맥스로 락걸려서 오래 걸리나??
        - DNS log
            - 얘는 정상 작동함
                - 
            - ERROR] DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input synta 
        - watch metric 
            - ERROR] DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input synta 
            - 
    - 람다 실패 플랜 만들기
        - 실패 데이터 별도 저장
            - SQS, SNS
        - Watch 에 람다 실패 경고..
        - 
    - start, end 파싱 다시 하기 
        - 
        - 
    - 
    - 스키마 변경
        - tz 값 떼기
    - 
    - 옮기기
        - 새 테이블 만들기
            - seq  시작  with room 
        - lambda 저장 위치 변경
            - 
        - pg dump, pg_restore
            - 
    - 
- PHASE 2 13-16 / 6
    - \~~~~
- PHASE 3 16-18 / 4
    - 

### 22-12-07 수

- PHASE 1 9-12 / 6
    - 람다 개선
    - 
    - 람다 실패 플랜 
        - 실패 데이터 별도 저장
            - SQS, SNS
        - Watch 에 람다 실패 경고..
        - 
    - timestamp 값 변경
        - 기존
            - boto3 response time
        - 이후
            - kinesis Insert Time
            - 
    - 람다 에러
        - streamToRDB
            - Task timed out 
                - 이벤트 7개 처리에
                    - 10초 넘기기 시작
                    - 왜...?
                - DB 커넥션 풀 맥스로 락걸려서 오래 걸리나??
            - 실패시 쪼개서 작업 들어감
        - watch metric 
            - [ERROR] DataError: (psycopg2.errors.NumericValueOutOfRange) integer out of range
                - Integer to Float 
        - vpc flow log
            - DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type bigint: "-"
                - bytes
                - 빈값 '-'처리 필요함
                    - df 처리 
            - Task timed out after 10.08 seconds
                -  에러 쌓이기 시작하다가, 누적되면서 파싱하는데 시간소모되서 해결 못함
                - 램 증설 또는 레코드 사이즈 조절
                    - 50 -> 10
                    - 192 -> 320
            - start, end  수정하기
                - 
        - DNS log
            - 얘는 정상 작동함
    - 
    - 스키마 변경
        - tz 값 떼기
            - ~~vpc~~
            - ~~dns~~
            - ~~watch~~
            - ~~trail~~
    - timestamp  설명
        - kinesis timestamp 
            - 
        - cloudwatch event timestamp
            - vpc_flowlog
            - dns_log
            - cloudtrail 
        - self timestamp
            - cloudwatch metric
        - 
    - 옮기기
        - 새 테이블 만들기
            - seq  시작  with Space
                - vpc
                - dns
                - watch
                - trail
        - lambda 저장 위치 변경
            - schema log_data2
            - ~~vpc~~
            - ~~dns~~
            - ~~watch~~
            - ~~trail~~
        - Last Event Time
            - pg dump, pg_restore
- PHASE 2 13-16 / 6
    - \~~~~
- PHASE 3 16-18 / 4
    - 

### 22-12-08 목

- PHASE 1 9-12 / 6
    - 람다 에러 확인 3 | 3
        - vpc 
            - lambda 에러 4건 발생함
                -  DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type bigint: "-"
                - LINE 1: ...'::timestamp), ('779205805467', '-', 'apne2-az3', '-', '-', ...
            - srcport", "dstport", "protocol", "packets", "bytes
            - Fix dataframe data manu
        - watch metric 에러 확인하기
            - 32.16166666666667
            - 6929178624.0 => 여기서 에러가 발생함
            - 0.67796610168505
    - 할일정리
        - 데이터 변경
            - 칼럼네임 변경
                - timestamp -> timestamp_tz, 
                - event_time -> event_time_utc
        - 수집방법들 검증
            - vpc, dns -> s3 수집 추가
                - VPC
                    - Cloudwatch
                    - S3
                    - KinesisFirehose
                - DNS
                    - Cloudwatch
                    - S3
                    - KinesisFirehose
            - 테스트 
                - 가설
                    - 람다에는 키네시스에서 어떻게 컨슘 하는지가 나와 있지 않다.
                    - 단지 연결만 시킬 뿐이다. 
                    - 람다 코드가 업데이트 될 경우, 키네시스 어디서 가져올지 어떻게 알것인가?
                    - 키네시스와 람다 사이에 키네시스에서 컨슘하고 람다로 집어넣는 작업을 해주는 매니저가 있을 것을 추정된다.
                    - 
                - 키네시스 수집 정지했다가 재가동할시 데이터 이어서 수집이 되는지?
                    - 동일한 람다 함수를 만들어 놓고 중간에 kinesis  disable -> enable 시켜봄
                    - 중간에 3분정도 disable 시켰다가 다시 enable 시켜도 
                        - disable 시간 포함 같은 갯수의 데이터 보유하고 있음
                - 결론
                    - 람다 업데이트시, 
                        - Kinesis 트리거 Disable
                        - Lambda Update
                        - Kinesis Enable
                        - 
        - 트레일, 기존 수집과 새 수집 데이터 정합성 비교 해보기
            - 쉬지 않고 수집한 내역
            - count event_id
        - 
        - Credit 수집 방법 대안들 탐색
            - 
        - 데이터 관리 정책 생각해보기
            - 
        - 람다 에러대응 테스트 해보기
            - 재시도 횟수
            - 배치 사이즈 비교
        - VPC, DNS 데이터 분석
            - 
- PHASE 2 13-16 / 6
    - \~~~~
- PHASE 3 16-18 / 4
    - 

### 22-12-09 금

- PHASE 1 9-12 / 6
    - Lambda 에러
        - [ERROR] DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type integer: "-"
        - LINE 1: ...2', '-', 0, '-', '-', 'subnet-0ca8c34aa6ff75926', '-', '-', ...
    - 키네시스-람다 연결성테스트 
        - 가설
            - 람다에는 키네시스에서 어떻게 컨슘 하는지가 나와 있지 않다.
            - 단지 연결만 시킬 뿐이다. 
            - 람다 코드가 업데이트 될 경우, 키네시스 어디서 가져올지 어떻게 알것인가?
            - 키네시스와 람다 사이에 키네시스에서 컨슘하고 람다로 집어넣는 작업을 해주는 매니저가 있을 것을 추정된다.
            - 
        - 키네시스 수집 정지했다가 재가동할시 데이터 이어서 수집이 되는지?
            - 동일한 람다 함수를 만들어 놓고 중간에 kinesis  disable -> enable 시켜봄
            - 중간에 3분정도 disable 시켰다가 다시 enable 시켜도 
                - disable 시간 포함 같은 갯수의 데이터 보유하고 있음
        - 결론
            - 람다 업데이트시, 
                - Kinesis 트리거 Disable
                - Lambda Update
                - Kinesis Enable
                - 
    - 데이터 변경
        - 칼럼네임 변경
            - timestamp -> timestamp_tz, 
            - event_time -> event_time_utc``
    - 람다 에러대응 테스트 해보기
        - 문서 찾아보기
        - 배치 사이즈 비교
        - 재시도 횟수
    - 
    - cloudwatch metric 중복 확인
        - 동일 데이터 한번에 9개가 저장 되는 이유는 뭘까?
            - watch metric 에서 계속 쏘고 있음 => 아님
        - 
    - VPC, DNS 데이터 분석
        - 
    - Credit 수집 방법 대안들 탐색
        - 
- PHASE 2 13-16 / 6
    - \~~~~
- PHASE 3 16-18 / 4
    - 


## TEL (Trial and Error Log)

### 22-12-07

- ERROR: lambda timed out
    - SITUATION: AWS lambda running
    - REASON:
        - Data hadling time exceed the limit: 10s 
        - because cpu is limited by allocated ram size
    - SOLUTION:
        - set options for failure
            - retire count
            - split data when fail
- ERROR: Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Index(['start_utc, end_utc'], dtype='object').
    - SITUATION:
        - df multi column tz.localize 
    - REASON:
        - spelling Error
    - SOLUTION:
        - "start_utc", "end_utc" <== "start_utc, end_utc" 

### 22-12-08

- ERROR: DataError: (psycopg2.errors.NumericValueOutOfRange) integer out of range
    - SITUATION: cloudwatch metric -> RDB lambda
        - 
    - REASON: column type 데이터 안맞음
        - 6929178624.0
        - 에서 에러남
    - SOLUTION:
        - colum Type
            - FLOAT <== Int4